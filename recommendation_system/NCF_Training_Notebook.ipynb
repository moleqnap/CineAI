{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Collaborative Filtering for Movie Recommendations\n",
    "\n",
    "Bu notebook, React uygulamasından toplanan kullanıcı puanlamalarını kullanarak Neural Collaborative Filtering (NCF) modeli eğitir.\n",
    "\n",
    "## Adımlar:\n",
    "1. Veri yükleme ve ön işleme\n",
    "2. Model mimarisi oluşturma\n",
    "3. Model eğitimi\n",
    "4. Değerlendirme ve görselleştirme\n",
    "5. Öneri üretme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri yükle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Görselleştirme ayarları\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Kütüphaneler yüklendi!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Veri Yükleme ve Keşif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# React uygulamasından dışa aktarılan JSON dosyasını yükle\n",
    "# Not: 'ratings.json' dosyasını bu notebook ile aynı klasöre koyun\n",
    "\n",
    "def load_ratings_data(filepath='ratings.json'):\n",
    "    \"\"\"JSON dosyasından puanlama verilerini yükle\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        return data['ratings']\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Dosya bulunamadı: {filepath}\")\n",
    "        print(\"Örnek veri oluşturuluyor...\")\n",
    "        return generate_sample_data()\n",
    "\n",
    "def generate_sample_data():\n",
    "    \"\"\"Test için örnek veri oluştur\"\"\"\n",
    "    sample_ratings = []\n",
    "    users = [f\"user_{i}\" for i in range(1, 26)]  # 25 kullanıcı\n",
    "    items = list(range(1, 21))  # 20 içerik\n",
    "    \n",
    "    for user in users:\n",
    "        # Her kullanıcı 8-15 rastgele içeriği puanlar\n",
    "        num_ratings = np.random.randint(8, 16)\n",
    "        user_items = np.random.choice(items, num_ratings, replace=False)\n",
    "        \n",
    "        for item in user_items:\n",
    "            # Gerçekçi puanlama dağılımı (daha çok 3-5 yıldız)\n",
    "            rating = np.random.choice([1, 2, 3, 4, 5], p=[0.1, 0.1, 0.2, 0.3, 0.3])\n",
    "            sample_ratings.append({\n",
    "                'userId': user,\n",
    "                'itemId': int(item),\n",
    "                'rating': int(rating),\n",
    "                'timestamp': 1234567890,\n",
    "                'contentType': 'movie'\n",
    "            })\n",
    "    \n",
    "    return sample_ratings\n",
    "\n",
    "# Veriyi yükle\n",
    "ratings_data = load_ratings_data()\n",
    "df = pd.DataFrame(ratings_data)\n",
    "\n",
    "print(f\"Toplam puanlama sayısı: {len(df)}\")\n",
    "print(f\"Benzersiz kullanıcı sayısı: {df['userId'].nunique()}\")\n",
    "print(f\"Benzersiz içerik sayısı: {df['itemId'].nunique()}\")\n",
    "print(f\"Ortalama puanlama: {df['rating'].mean():.2f}\")\n",
    "\n",
    "# İlk 5 satırı göster\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri keşfi ve görselleştirme\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Puanlama dağılımı\n",
    "axes[0, 0].hist(df['rating'], bins=5, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Puanlama Dağılımı')\n",
    "axes[0, 0].set_xlabel('Puanlama')\n",
    "axes[0, 0].set_ylabel('Frekans')\n",
    "\n",
    "# Kullanıcı başına puanlama sayısı\n",
    "user_counts = df['userId'].value_counts()\n",
    "axes[0, 1].hist(user_counts, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[0, 1].set_title('Kullanıcı Başına Puanlama Sayısı')\n",
    "axes[0, 1].set_xlabel('Puanlama Sayısı')\n",
    "axes[0, 1].set_ylabel('Kullanıcı Sayısı')\n",
    "\n",
    "# İçerik başına puanlama sayısı\n",
    "item_counts = df['itemId'].value_counts()\n",
    "axes[1, 0].hist(item_counts, bins=20, alpha=0.7, color='salmon', edgecolor='black')\n",
    "axes[1, 0].set_title('İçerik Başına Puanlama Sayısı')\n",
    "axes[1, 0].set_xlabel('Puanlama Sayısı')\n",
    "axes[1, 0].set_ylabel('İçerik Sayısı')\n",
    "\n",
    "# Kullanıcı-İçerik matrisi sparsity\n",
    "total_possible_ratings = df['userId'].nunique() * df['itemId'].nunique()\n",
    "actual_ratings = len(df)\n",
    "sparsity = (1 - actual_ratings / total_possible_ratings) * 100\n",
    "\n",
    "axes[1, 1].bar(['Mevcut Puanlamalar', 'Eksik Puanlamalar'], \n",
    "               [actual_ratings, total_possible_ratings - actual_ratings],\n",
    "               color=['lightblue', 'lightcoral'])\n",
    "axes[1, 1].set_title(f'Veri Seyrekliği: {sparsity:.1f}%')\n",
    "axes[1, 1].set_ylabel('Puanlama Sayısı')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nVeri İstatistikleri:\")\n",
    "print(f\"Toplam olası puanlama: {total_possible_ratings:,}\")\n",
    "print(f\"Mevcut puanlama: {actual_ratings:,}\")\n",
    "print(f\"Veri seyrekliği: {sparsity:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Veri Ön İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kullanıcı ve içerik ID'lerini sayısal değerlere dönüştür\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "df['user_encoded'] = user_encoder.fit_transform(df['userId'])\n",
    "df['item_encoded'] = item_encoder.fit_transform(df['itemId'])\n",
    "\n",
    "num_users = df['user_encoded'].nunique()\n",
    "num_items = df['item_encoded'].nunique()\n",
    "\n",
    "print(f\"Kodlanmış kullanıcı sayısı: {num_users}\")\n",
    "print(f\"Kodlanmış içerik sayısı: {num_items}\")\n",
    "\n",
    "# Eğitim ve test verilerini ayır\n",
    "X = {\n",
    "    'user_id': df['user_encoded'].values,\n",
    "    'item_id': df['item_encoded'].values\n",
    "}\n",
    "y = df['rating'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    [X['user_id'], X['item_id']], y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train = {'user_id': X_train[0], 'item_id': X_train[1]}\n",
    "X_test = {'user_id': X_test[0], 'item_id': X_test[1]}\n",
    "\n",
    "print(f\"\\nEğitim verisi boyutu: {len(y_train)}\")\n",
    "print(f\"Test verisi boyutu: {len(y_test)}\")\n",
    "\n",
    "# Kodlama örnekleri\n",
    "print(f\"\\nKodlama Örnekleri:\")\n",
    "for i in range(3):\n",
    "    original_user = df.iloc[i]['userId']\n",
    "    encoded_user = df.iloc[i]['user_encoded']\n",
    "    original_item = df.iloc[i]['itemId']\n",
    "    encoded_item = df.iloc[i]['item_encoded']\n",
    "    print(f\"Kullanıcı: {original_user} -> {encoded_user}, İçerik: {original_item} -> {encoded_item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural Collaborative Filtering Model Mimarisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ncf_model(num_users, num_items, embedding_size=50, hidden_units=[128, 64]):\n",
    "    \"\"\"\n",
    "    Neural Collaborative Filtering modeli oluştur\n",
    "    \n",
    "    Args:\n",
    "        num_users: Benzersiz kullanıcı sayısı\n",
    "        num_items: Benzersiz içerik sayısı\n",
    "        embedding_size: Embedding vektör boyutu\n",
    "        hidden_units: Gizli katman boyutları\n",
    "    \"\"\"\n",
    "    # Giriş katmanları\n",
    "    user_input = Input(shape=(), name='user_id')\n",
    "    item_input = Input(shape=(), name='item_id')\n",
    "    \n",
    "    # Embedding katmanları\n",
    "    user_embedding = Embedding(num_users, embedding_size, name='user_embedding')(user_input)\n",
    "    item_embedding = Embedding(num_items, embedding_size, name='item_embedding')(item_input)\n",
    "    \n",
    "    # Embedding'leri düzleştir\n",
    "    user_vec = Flatten(name='user_flatten')(user_embedding)\n",
    "    item_vec = Flatten(name='item_flatten')(item_embedding)\n",
    "    \n",
    "    # Kullanıcı ve içerik vektörlerini birleştir\n",
    "    concat = Concatenate(name='concat')([user_vec, item_vec])\n",
    "    \n",
    "    # Gizli katmanlar (dropout ile)\n",
    "    x = concat\n",
    "    for i, units in enumerate(hidden_units):\n",
    "        x = Dense(units, activation='relu', name=f'dense_{i+1}')(x)\n",
    "        x = Dropout(0.2, name=f'dropout_{i+1}')(x)\n",
    "    \n",
    "    # Çıkış katmanı (puanlama tahmini)\n",
    "    output = Dense(1, activation='sigmoid', name='rating_output')(x)\n",
    "    \n",
    "    # Çıkışı puanlama aralığına ölçekle (1-5)\n",
    "    output = tf.keras.layers.Lambda(lambda x: x * 4 + 1, name='scale_output')(output)\n",
    "    \n",
    "    # Modeli oluştur\n",
    "    model = Model(inputs=[user_input, item_input], outputs=output)\n",
    "    \n",
    "    # Modeli derle\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Modeli oluştur\n",
    "embedding_size = 50\n",
    "hidden_units = [128, 64]\n",
    "\n",
    "model = build_ncf_model(num_users, num_items, embedding_size, hidden_units)\n",
    "\n",
    "# Model özetini göster\n",
    "model.summary()\n",
    "\n",
    "# Model mimarisini görselleştir\n",
    "tf.keras.utils.plot_model(model, to_file='ncf_model.png', show_shapes=True, show_layer_names=True)\n",
    "print(\"\\nModel mimarisi 'ncf_model.png' dosyasına kaydedildi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Eğitimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim parametreleri\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "validation_split = 0.2\n",
    "\n",
    "# Callback'ler\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_ncf_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "print(\"Model eğitimi başlıyor...\")\n",
    "print(f\"Epochs: {epochs}, Batch Size: {batch_size}\")\n",
    "print(f\"Embedding Size: {embedding_size}, Hidden Units: {hidden_units}\")\n",
    "\n",
    "# Modeli eğit\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=validation_split,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nEğitim tamamlandı!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Eğitim Sonuçlarını Görselleştir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim geçmişini görselleştir\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss grafiği\n",
    "ax1.plot(history.history['loss'], label='Eğitim Loss', linewidth=2)\n",
    "ax1.plot(history.history['val_loss'], label='Doğrulama Loss', linewidth=2)\n",
    "ax1.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# MAE grafiği\n",
    "ax2.plot(history.history['mae'], label='Eğitim MAE', linewidth=2)\n",
    "ax2.plot(history.history['val_mae'], label='Doğrulama MAE', linewidth=2)\n",
    "ax2.set_title('Model MAE', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('MAE')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# En iyi sonuçları yazdır\n",
    "best_epoch = np.argmin(history.history['val_loss'])\n",
    "print(f\"\\nEn İyi Sonuçlar (Epoch {best_epoch + 1}):\")\n",
    "print(f\"Eğitim Loss: {history.history['loss'][best_epoch]:.4f}\")\n",
    "print(f\"Doğrulama Loss: {history.history['val_loss'][best_epoch]:.4f}\")\n",
    "print(f\"Eğitim MAE: {history.history['mae'][best_epoch]:.4f}\")\n",
    "print(f\"Doğrulama MAE: {history.history['val_mae'][best_epoch]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Değerlendirmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test verisi üzerinde tahmin yap\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Metrikleri hesapla\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Test Verisi Performansı:\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Tahmin vs Gerçek değerler grafiği\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Scatter plot\n",
    "ax1.scatter(y_test, y_pred, alpha=0.6, s=30)\n",
    "ax1.plot([1, 5], [1, 5], 'r--', linewidth=2)\n",
    "ax1.set_xlabel('Gerçek Puanlama')\n",
    "ax1.set_ylabel('Tahmin Edilen Puanlama')\n",
    "ax1.set_title('Tahmin vs Gerçek Değerler')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Hata dağılımı\n",
    "errors = y_test - y_pred.flatten()\n",
    "ax2.hist(errors, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "ax2.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('Hata (Gerçek - Tahmin)')\n",
    "ax2.set_ylabel('Frekans')\n",
    "ax2.set_title('Hata Dağılımı')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Puanlama bazında performans\n",
    "rating_performance = []\n",
    "for rating in range(1, 6):\n",
    "    mask = y_test == rating\n",
    "    if np.sum(mask) > 0:\n",
    "        rating_mae = mean_absolute_error(y_test[mask], y_pred[mask])\n",
    "        rating_performance.append({\n",
    "            'rating': rating,\n",
    "            'count': np.sum(mask),\n",
    "            'mae': rating_mae\n",
    "        })\n",
    "\n",
    "rating_df = pd.DataFrame(rating_performance)\n",
    "print(f\"\\nPuanlama Bazında Performans:\")\n",
    "print(rating_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Öneri Üretme Fonksiyonları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(model, user_encoder, item_encoder, user_id, item_id):\n",
    "    \"\"\"\n",
    "    Belirli bir kullanıcı-içerik çifti için puanlama tahmini yap\n",
    "    \"\"\"\n",
    "    try:\n",
    "        user_encoded = user_encoder.transform([user_id])[0]\n",
    "        item_encoded = item_encoder.transform([item_id])[0]\n",
    "        \n",
    "        prediction = model.predict({\n",
    "            'user_id': np.array([user_encoded]),\n",
    "            'item_id': np.array([item_encoded])\n",
    "        }, verbose=0)\n",
    "        \n",
    "        return float(prediction[0][0])\n",
    "    except ValueError:\n",
    "        # Kullanıcı veya içerik eğitim verisinde yok\n",
    "        return 3.0  # Varsayılan puanlama\n",
    "\n",
    "def recommend_items(model, user_encoder, item_encoder, user_id, num_recommendations=10):\n",
    "    \"\"\"\n",
    "    Bir kullanıcı için içerik önerileri üret\n",
    "    \"\"\"\n",
    "    try:\n",
    "        user_encoded = user_encoder.transform([user_id])[0]\n",
    "    except ValueError:\n",
    "        # Yeni kullanıcı - popüler içerikleri döndür\n",
    "        return list(item_encoder.classes_[:num_recommendations])\n",
    "    \n",
    "    # Tüm içerikler için tahmin yap\n",
    "    all_items = item_encoder.classes_\n",
    "    item_predictions = []\n",
    "    \n",
    "    for item_id in all_items:\n",
    "        try:\n",
    "            item_encoded = item_encoder.transform([item_id])[0]\n",
    "            prediction = model.predict({\n",
    "                'user_id': np.array([user_encoded]),\n",
    "                'item_id': np.array([item_encoded])\n",
    "            }, verbose=0)\n",
    "            \n",
    "            item_predictions.append({\n",
    "                'itemId': item_id,\n",
    "                'predicted_rating': float(prediction[0][0])\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Tahmin edilen puanlamaya göre sırala\n",
    "    item_predictions.sort(key=lambda x: x['predicted_rating'], reverse=True)\n",
    "    \n",
    "    # En iyi önerileri döndür\n",
    "    return [item['itemId'] for item in item_predictions[:num_recommendations]]\n",
    "\n",
    "def get_user_recommendations_with_scores(model, user_encoder, item_encoder, user_id, num_recommendations=10):\n",
    "    \"\"\"\n",
    "    Kullanıcı için önerileri puanlarıyla birlikte döndür\n",
    "    \"\"\"\n",
    "    try:\n",
    "        user_encoded = user_encoder.transform([user_id])[0]\n",
    "    except ValueError:\n",
    "        return []\n",
    "    \n",
    "    all_items = item_encoder.classes_\n",
    "    item_predictions = []\n",
    "    \n",
    "    for item_id in all_items:\n",
    "        try:\n",
    "            item_encoded = item_encoder.transform([item_id])[0]\n",
    "            prediction = model.predict({\n",
    "                'user_id': np.array([user_encoded]),\n",
    "                'item_id': np.array([item_encoded])\n",
    "            }, verbose=0)\n",
    "            \n",
    "            item_predictions.append({\n",
    "                'itemId': item_id,\n",
    "                'predicted_rating': float(prediction[0][0])\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Tahmin edilen puanlamaya göre sırala\n",
    "    item_predictions.sort(key=lambda x: x['predicted_rating'], reverse=True)\n",
    "    \n",
    "    return item_predictions[:num_recommendations]\n",
    "\n",
    "print(\"Öneri fonksiyonları tanımlandı!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Örnek Öneriler Üret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rastgele birkaç kullanıcı için öneriler üret\n",
    "sample_users = list(user_encoder.classes_)[:5]\n",
    "\n",
    "print(\"Örnek Kullanıcı Önerileri:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for user_id in sample_users:\n",
    "    print(f\"\\nKullanıcı: {user_id}\")\n",
    "    \n",
    "    # Kullanıcının mevcut puanlamaları\n",
    "    user_ratings = df[df['userId'] == user_id][['itemId', 'rating']].sort_values('rating', ascending=False)\n",
    "    print(f\"Mevcut puanlamaları ({len(user_ratings)} adet):\")\n",
    "    for _, row in user_ratings.head(3).iterrows():\n",
    "        print(f\"  İçerik {row['itemId']}: {row['rating']} yıldız\")\n",
    "    \n",
    "    # Öneriler (puanlarıyla birlikte)\n",
    "    recommendations = get_user_recommendations_with_scores(model, user_encoder, item_encoder, user_id, 5)\n",
    "    \n",
    "    # Kullanıcının daha önce puanlamadığı içerikleri filtrele\n",
    "    rated_items = set(user_ratings['itemId'].values)\n",
    "    new_recommendations = [rec for rec in recommendations if rec['itemId'] not in rated_items]\n",
    "    \n",
    "    print(f\"Yeni öneriler:\")\n",
    "    for i, rec in enumerate(new_recommendations[:3], 1):\n",
    "        print(f\"  {i}. İçerik {rec['itemId']}: {rec['predicted_rating']:.2f} tahmin puanı\")\n",
    "    \n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model ve Encoderları Kaydet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Modeli kaydet\n",
    "model.save('ncf_recommendation_model.h5')\n",
    "print(\"Model 'ncf_recommendation_model.h5' dosyasına kaydedildi.\")\n",
    "\n",
    "# Encoderları kaydet\n",
    "with open('encoders.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'user_encoder': user_encoder,\n",
    "        'item_encoder': item_encoder\n",
    "    }, f)\n",
    "print(\"Encoderlar 'encoders.pkl' dosyasına kaydedildi.\")\n",
    "\n",
    "# Model bilgilerini kaydet\n",
    "model_info = {\n",
    "    'num_users': num_users,\n",
    "    'num_items': num_items,\n",
    "    'embedding_size': embedding_size,\n",
    "    'hidden_units': hidden_units,\n",
    "    'test_mse': float(mse),\n",
    "    'test_mae': float(mae),\n",
    "    'test_rmse': float(rmse)\n",
    "}\n",
    "\n",
    "with open('model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "print(\"Model bilgileri 'model_info.json' dosyasına kaydedildi.\")\n",
    "\n",
    "print(f\"\\nModel Özeti:\")\n",
    "print(f\"Kullanıcı sayısı: {num_users}\")\n",
    "print(f\"İçerik sayısı: {num_items}\")\n",
    "print(f\"Embedding boyutu: {embedding_size}\")\n",
    "print(f\"Gizli katmanlar: {hidden_units}\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Yeni Kullanıcı için Öneri Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeni bir kullanıcı ID'si ile test\n",
    "test_user_id = \"new_user_123\"\n",
    "test_item_id = 1\n",
    "\n",
    "print(f\"Yeni kullanıcı testi: {test_user_id}\")\n",
    "\n",
    "# Puanlama tahmini (yeni kullanıcı için varsayılan değer dönecek)\n",
    "predicted_rating = predict_rating(model, user_encoder, item_encoder, test_user_id, test_item_id)\n",
    "print(f\"İçerik {test_item_id} için tahmin edilen puanlama: {predicted_rating:.2f}\")\n",
    "\n",
    "# Öneriler (yeni kullanıcı için popüler içerikler dönecek)\n",
    "recommendations = recommend_items(model, user_encoder, item_encoder, test_user_id, 5)\n",
    "print(f\"Önerilen içerikler: {recommendations}\")\n",
    "\n",
    "# Mevcut bir kullanıcı ile karşılaştırma\n",
    "existing_user = sample_users[0]\n",
    "existing_recommendations = recommend_items(model, user_encoder, item_encoder, existing_user, 5)\n",
    "print(f\"\\nMevcut kullanıcı ({existing_user}) önerileri: {existing_recommendations}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EĞİTİMİ TAMAMLANDI!\")\n",
    "print(\"=\"*60)\n",
    "print(\"Dosyalar:\")\n",
    "print(\"- ncf_recommendation_model.h5 (Eğitilmiş model)\")\n",
    "print(\"- encoders.pkl (Kullanıcı/İçerik encoderları)\")\n",
    "print(\"- model_info.json (Model bilgileri)\")\n",
    "print(\"- best_ncf_model.h5 (En iyi model checkpoint)\")\n",
    "print(\"\\nBu dosyaları React uygulamanızla entegre edebilirsiniz!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}